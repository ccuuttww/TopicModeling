{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture news from RTHK news website with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from calendar import monthrange\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "year=2020\n",
    "\n",
    "def number_of_days_in_month(year=2020, month=2):\n",
    "    return monthrange(year, month)[1]\n",
    "\n",
    "\n",
    "\n",
    "def capture(year=2021):\n",
    "    domain = \"https://news.rthk.hk\"\n",
    "    csv_file = open(f'RTHK_news_{year}.csv', 'w', encoding=\"utf-8\")\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Title','Corpus'])\n",
    "    for i in range(1,13):\n",
    "        num_of_days = number_of_days_in_month(year, i)\n",
    "        print(f\"Capturing month {str(i)}\")\n",
    "        if len(str(i))<2:        \n",
    "            month = \"0\"+str(i)\n",
    "\n",
    "        for j in range(1,num_of_days):\n",
    "            day = str(j)\n",
    "            if len(day)<2:\n",
    "                day = \"0\"+day\n",
    "\n",
    "            link = f'https://news.rthk.hk/rthk/en/news-archive.htm?archive_year={year}&archive_month={month}&archive_day={day}&archive_cat=8'        \n",
    "            source = requests.get(link).text\n",
    "            soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "            for span in soup.find_all('span',class_='title'):\n",
    "                corpus_link = domain+span.a.attrs['href']\n",
    "\n",
    "                # get corpus\n",
    "                source = requests.get(corpus_link).text\n",
    "                soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "                div = soup.find('div')\n",
    "                div_cls = div.find('div',class_='itemFullText')\n",
    "                div_totext = str(div_cls.prettify())\n",
    "\n",
    "\n",
    "                remove_tag = re.compile('<.*?>')\n",
    "                unformat_text = re.sub(remove_tag,'',div_totext)\n",
    "                plain_text = re.sub('\\s+', ' ', unformat_text)                       \n",
    "                csv_writer.writerow([str(span.a.contents[0]),str(plain_text)])\n",
    "\n",
    "    csv_file.close()\n",
    "#capture(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Load RTHK news of 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def readcsv(file):\n",
    "    RTHK_news = pd.read_csv(file, encoding = \"utf-8\")\n",
    "    return RTHK_news\n",
    "\n",
    "RTHK_news = readcsv(\"RTHK_news_2020_old.csv\")\n",
    "print(len(RTHK_news))\n",
    "RTHK_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Remove unnecessary text and feature with regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# process with regular expression\n",
    "a = RTHK_news.Corpus\n",
    "\n",
    "# remove synatx like ______________________________ Last updated: 2021-01-02 HKT 17:10 \n",
    "a = a.map(lambda x: re.sub('[_]+\\s[A-Za-z]+\\s[a-z]+:\\s[-0-9]+\\s[A-Z]+\\s[:0-9]+',\"\", x))\n",
    "\n",
    "# remove all punctuation\n",
    "a = a.map(lambda x: re.sub('[”“–,\\.!?\\\"\\(\\)\\-\\[\\]\\{\\};:|<>@$%^&*_~\\`]',\"\", x))\n",
    "\n",
    "# remove all digit\n",
    "a = a.map(lambda x: re.sub('[0-9]+',\"\", x))\n",
    "\n",
    "# remove all double space\n",
    "a = a.map(lambda x: re.sub('\\s+', ' ', x))\n",
    "\n",
    "# all lower case\n",
    "a = a.map(lambda x: x.lower())\n",
    "\n",
    "# replace ’ with '\n",
    "a = a.map(lambda x: re.sub('’',\"'\", x))\n",
    "\n",
    "# replace 'news reporter'  with  news reporter\n",
    "a = a.map(lambda x: re.sub('\\'(([a-z]+\\s)*[a-z]+)\\'',r'\\1',x))\n",
    "\n",
    "# remove head and tail space of corpus\n",
    "a = a.map(lambda x: re.sub(r\"^\\s+|\\s+$\", \"\", x))\n",
    "\n",
    "# final corpus\n",
    "p_corpus = a.copy()\n",
    "\n",
    "print(p_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Remove Stop word and tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "def add_stop_words(nlp,words):\n",
    "    for i in range(len(words)):\n",
    "        nlp.Defaults.stop_words.add(words[i])\n",
    "    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "def spacy_tokenizer_(sentence,stop_words):\n",
    "    \n",
    "    parser = English()\n",
    "\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "    \n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "        \n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words]\n",
    "    \n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens\n",
    "\n",
    "\n",
    "stop_words = add_stop_words(spacy.load('en_core_web_sm'),['hong','kong','said','saying','people','hk'])\n",
    "tokenize_text = p_corpus.apply(lambda x:spacy_tokenizer_(x,stop_words))\n",
    "print(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Make dictionary and document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models,corpora\n",
    "\n",
    "def gensim_dict_term_matrix(text):\n",
    "    \n",
    "    dictionary = corpora.Dictionary(text)\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in text]\n",
    "    \n",
    "    return dictionary,doc_term_matrix\n",
    " \n",
    "\n",
    "# Make Dictionary and Dictionary - Term Matrix \n",
    "dictionary, doc_term_matrix = gensim_dict_term_matrix(tokenize_text)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Function start in here if u want to view the result please go to the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook,tnrange,tqdm\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# return the range form lower no of topics to upper no of topics\n",
    "def topic_list(lower,upper):\n",
    "    return np.arange(lower,upper)\n",
    "\n",
    "\n",
    "\n",
    "# Get topic distribution on each corpus\n",
    "def topic_distribution(lda, doc_term_matrix):\n",
    "    \n",
    "    topic_dis_perdoc = lda.get_document_topics(doc_term_matrix)\n",
    "    return topic_dis_perdoc\n",
    "\n",
    "\n",
    "\n",
    "# Save the document into csv file with the most possible topics\n",
    "def classify_corpus(best_topics, topic_dis_perdoc ,corpus_len):\n",
    "    \n",
    "    # assign Topic_corpus\n",
    "    Topic_corpus={}    \n",
    "    for r in range(best_topics):       \n",
    "        Topic_corpus[r]={'Title':[], 'Corpus':[]}    \n",
    "    \n",
    "    for k in range(corpus_len):        \n",
    "        index_topic = 0\n",
    "        largest = 0 \n",
    "        \n",
    "        for l in topic_dis_perdoc[k]:\n",
    "\n",
    "            if l[1] > largest:\n",
    "                largest = l[1]\n",
    "                index_topic = l[0]\n",
    "\n",
    "        Topic_corpus[index_topic]['Title'].append(RTHK_news.Title[k])\n",
    "        Topic_corpus[index_topic]['Corpus'].append(RTHK_news.Corpus[k])\n",
    "    \n",
    "    return Topic_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Optimize with ntopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best lda object\n",
    "def find_optimize_with_ntopic(num_topics_list, doc_term_matrix, dictionary):  \n",
    "    \n",
    "    Lda = models.LdaMulticore\n",
    "    \n",
    "    # umass coherence score\n",
    "    coherenceList_umass = []\n",
    "    \n",
    "    # for save lda object\n",
    "    lda_array = []\n",
    " \n",
    "    for num_topics in tqdm(num_topics_list):\n",
    "        \n",
    "        lda= Lda(doc_term_matrix, num_topics=num_topics,id2word = dictionary,    \n",
    "        passes=20,chunksize=4000,random_state=43)\n",
    "    \n",
    "        lda_array.append(lda)\n",
    "        cm = CoherenceModel(model=lda, corpus=doc_term_matrix, dictionary=dictionary, coherence='u_mass')\n",
    "        \n",
    "        coherenceList_umass.append(cm.get_coherence())\n",
    "        \n",
    "    return coherenceList_umass, lda_array\n",
    "\n",
    "\n",
    "\n",
    "# find best topic with smallest_coherence score\n",
    "def find_best_topics(coherenceList_umass,num_topics_list):\n",
    "\n",
    "    best_topics = num_topics_list[0]\n",
    "    smallest_coherence = 0\n",
    "    for i,j in zip(coherenceList_umass,num_topics_list):\n",
    "        if i < smallest_coherence:\n",
    "            smallest_coherence = i\n",
    "            best_topics = j\n",
    "\n",
    "    return smallest_coherence, best_topics\n",
    "\n",
    "\n",
    "\n",
    "# Get the best lda object (for n topics method only)\n",
    "def get_lda_object(best_topics, least_topic, lda_array):\n",
    "    \n",
    "    return lda_array[best_topics-least_topic]\n",
    "\n",
    "\n",
    "\n",
    "# plot n topics\n",
    "def plot_topics_by_score(plot,num_topics_list,coherenceList_umass):\n",
    "    \n",
    "    # plot topics by score\n",
    "    plotData = pd.DataFrame({'Number of topics' : num_topics_list, 'CoherenceScore' : coherenceList_umass})\n",
    "    f, ax = plt.subplots(figsize=(10,6))\n",
    "    \n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.pointplot(x = 'Number of topics', y = 'CoherenceScore', data = plotData)\n",
    "    \n",
    "    plt.axhline(y = -3.9)\n",
    "    plt.title('Topic coherence')\n",
    "    \n",
    "    if plot : plt.savefig('Topic coherence plot.png')\n",
    "        \n",
    "        \n",
    "\n",
    "# find best topic with differnt number of topics only\n",
    "def optimize_by_topics(p_corpus, doc_term_matrix, dictionary, tokenize_text, mininum=3, maximum=8, plot=0):\n",
    "    \n",
    "    corpus_len = len(p_corpus)\n",
    "    num_topics_list = topic_list(mininum,maximum)\n",
    "    \n",
    "    if mininum < 3:\n",
    "        mininum = 3\n",
    "        \n",
    "    if maximum < 4:\n",
    "        maximum = 4\n",
    "                        \n",
    "    coherenceList_umass, lda_array = find_optimize_with_ntopic(num_topics_list,doc_term_matrix,dictionary)\n",
    "    smallest_coherence, best_topics= find_best_topics(coherenceList_umass,num_topics_list)\n",
    "        \n",
    "    if plot == 1:\n",
    "        \n",
    "        print(\"Best no of topics: \",best_topics)       \n",
    "        plot_topics_by_score(0,num_topics_list,coherenceList_umass)\n",
    "        \n",
    "                \n",
    "    # find the best lda object\n",
    "    lda_ntopics = get_lda_object(best_topics, 3, lda_array)\n",
    "        \n",
    "    # Topic distribution\n",
    "    topic_dis_perdoc = topic_distribution(lda_ntopics, doc_term_matrix) \n",
    "        \n",
    "    # Classified Topic_corpus with k topics\n",
    "    Topic_corpus = classify_corpus(best_topics, topic_dis_perdoc, corpus_len)\n",
    "        \n",
    "    return lda_ntopics, Topic_corpus, best_topics\n",
    "    \n",
    "a,b,c = optimize_by_topics(p_corpus, doc_term_matrix, dictionary, tokenize_text, mininum=3, maximum=8, plot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Optimize with n topics, alpha and beta(sometimes called eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha and beta\n",
    "def set_alpha_beta(min,max,range):\n",
    "    \n",
    "    # Alpha parameter from 0.01 to 1 with 0.3 interval\n",
    "    alpha = list(np.arange(0.01, 1, 0.3))\n",
    "    alpha.append('symmetric')\n",
    "    alpha.append('asymmetric')\n",
    "    \n",
    "    # Beta parameter from 0.01 to 1 with 0.3 interval\n",
    "    beta = list(np.arange(0.01, 1, 0.3))\n",
    "    beta.append('symmetric')\n",
    "    \n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "def compute_coherence_values(tokenize_text, corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenize_text, dictionary=dictionary, coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "\n",
    "\n",
    "def find_optimize_with_alpha_beta_ntopics(alpha, beta, topics_range, corpus, dictionary, tokenize_text):\n",
    "    \n",
    "    model_results = {'Topics': [],\n",
    "                     'Alpha': [],\n",
    "                     'Beta': [],\n",
    "                     'Coherence': []\n",
    "                    }\n",
    "    \n",
    "\n",
    "    for k in tqdm(topics_range):\n",
    "        for a in alpha:\n",
    "            for b in beta:\n",
    "                cv = compute_coherence_values(tokenize_text = tokenize_text,corpus = doc_term_matrix, dictionary = dictionary, k = k, a = a, b = b)\n",
    "                model_results['Topics'].append(k)\n",
    "                model_results['Alpha'].append(a)\n",
    "                model_results['Beta'].append(b)\n",
    "                model_results['Coherence'].append(cv)\n",
    "\n",
    "\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results_test.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# find largest tuning score\n",
    "def find_largest_tuning_score(tuning_result):\n",
    "    largest  =  0\n",
    "    largest_index =  0\n",
    "    for i,j in zip(tuning_result.index.values.astype(int),tuning_result.Coherence):\n",
    "        if j>largest:\n",
    "            largest = j\n",
    "            largest_index = i\n",
    "            \n",
    "    return largest_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_by_alpha_beta(p_corpus, doc_term_matrix, dictionary, tokenize_text, mininum=3, maximum=8, debug=1):\n",
    "\n",
    "    corpus_len = len(p_corpus)\n",
    "    num_topics_list = topic_list(mininum,maximum)\n",
    "    \n",
    "    if mininum < 3:\n",
    "        mininum = 3\n",
    "        \n",
    "    if maximum < 4:\n",
    "        maximum = 4\n",
    "\n",
    "    alpha,beta = set_alpha_beta(0.01,1,0.3) \n",
    "        \n",
    "    # Warning long processing time\n",
    "    if debug==0:        \n",
    "        find_optimize_with_alpha_beta_ntopics(alpha, beta, num_topics_list, doc_term_matrix, dictionary, tokenize_text)\n",
    "        \n",
    "    tuning_result = pd.read_csv('lda_tuning_results1.csv', encoding = \"utf-8\")\n",
    "    largest_index = find_largest_tuning_score(tuning_result)\n",
    "\n",
    "    \n",
    "        \n",
    "    # tune up parameter\n",
    "    tuneup_topics = int(tuning_result.Topics[largest_index])  \n",
    "\n",
    "    \n",
    "    # find best alpha\n",
    "    tuneup_alpha = tuning_result.Alpha[largest_index]              \n",
    "    if tuning_result.Alpha[largest_index] != ('symmetric' or 'asymmetric'):        \n",
    "        tuneup_alpha = float(tuning_result.Alpha[largest_index])\n",
    " \n",
    "\n",
    "    # find best beta       \n",
    "    tuneup_beta = tuning_result.Beta[largest_index]\n",
    "    if tuning_result.Beta[largest_index] != ('symmetric'or 'asymmetric'):\n",
    "        tuneup_beta = float(tuning_result.Beta[largest_index])        \n",
    "\n",
    "        \n",
    "    # Compute Lda\n",
    "    Lda = models.LdaMulticore\n",
    "    lda_alpha_beta = Lda(doc_term_matrix, num_topics= tuneup_topics, id2word = dictionary, alpha = tuneup_alpha, eta = tuneup_beta, passes = 20, chunksize = 4000, random_state = 43)\n",
    "        \n",
    "    # Topic distribution\n",
    "    topic_dis_perdoc = topic_distribution(lda_alpha_beta, doc_term_matrix)\n",
    "\n",
    "    # Classified Topic_corpus with k topics\n",
    "    Topic_corpus = classify_corpus(tuneup_topics, topic_dis_perdoc, corpus_len) \n",
    "    \n",
    "    return lda_alpha_beta, Topic_corpus, tuneup_topics\n",
    "\n",
    "\n",
    "d,e,f = optimize_by_alpha_beta(p_corpus, doc_term_matrix, dictionary, tokenize_text, mininum=3, maximum=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Save top 20 word-topic cdistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put all top 20 words of individual topics into a csv\n",
    "import os\n",
    "\n",
    "def save_top_words(directory, best_topics, lda, num_words, print_out = 0):\n",
    "    \n",
    "    Top_words={}\n",
    "    words = lda.show_topics(num_words=20)\n",
    "    directory = \"\\\\\" + directory\n",
    "    \n",
    "    for i in range(best_topics):\n",
    "        \n",
    "        index = f\"Topic{i}\"\n",
    "        Top_words[index] = words[i]\n",
    "    \n",
    "    # to csv\n",
    "    pd.DataFrame(Top_words).to_csv(f\"{os.getcwd()}{directory}\\Top Words.csv\", index=False)\n",
    "    \n",
    "    if print_out:\n",
    "        for i in Top_words:           \n",
    "            print(Top_words[i])\n",
    "            print(\" \")\n",
    "        \n",
    "\n",
    "\n",
    "#save_top_words(\"RTHK_ntopics\", f, d, num_words = 10, print_out = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Result:<br />\n",
    "Word topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 \n",
      " 0.022*\"students\" + 0.015*\"school\" + 0.015*\"schools\" + 0.011*\"education\" + 0.009*\"teachers\" + 0.006*\"classes\" + 0.006*\"secondary\" + 0.005*\"primary\" + 0.005*\"teacher\" + 0.004*\"exams\" + 0.004*\"children\" + 0.004*\"yeung\" + 0.004*\"bureau\" + 0.004*\"parents\" + 0.003*\"class\" + 0.002*\"teaching\" + 0.002*\"campus\" + 0.002*\"student\" + 0.002*\"pupils\" + 0.002*\"exam\" \n",
      "\n",
      "Topic 2 \n",
      " 0.008*\"legco\" + 0.007*\"government\" + 0.006*\"council\" + 0.006*\"lawmakers\" + 0.006*\"chan\" + 0.005*\"committee\" + 0.005*\"party\" + 0.005*\"year\" + 0.004*\"lawmaker\" + 0.004*\"lam\" + 0.004*\"meeting\" + 0.004*\"camp\" + 0.004*\"election\" + 0.004*\"executive\" + 0.004*\"public\" + 0.004*\"chief\" + 0.003*\"new\" + 0.003*\"years\" + 0.003*\"prodemocracy\" + 0.003*\"law\" \n",
      "\n",
      "Topic 3 \n",
      " 0.016*\"law\" + 0.013*\"police\" + 0.011*\"security\" + 0.011*\"national\" + 0.007*\"government\" + 0.005*\"officers\" + 0.004*\"new\" + 0.004*\"beijing\" + 0.004*\"court\" + 0.004*\"sar\" + 0.004*\"media\" + 0.003*\"mainland\" + 0.003*\"protests\" + 0.003*\"public\" + 0.003*\"lam\" + 0.003*\"statement\" + 0.003*\"chief\" + 0.003*\"china\" + 0.003*\"year\" + 0.003*\"rights\" \n",
      "\n",
      "Topic 4 \n",
      " 0.004*\"education\" + 0.004*\"question\" + 0.003*\"students\" + 0.002*\"land\" + 0.002*\"authority\" + 0.002*\"subject\" + 0.002*\"exam\" + 0.002*\"studies\" + 0.002*\"housing\" + 0.002*\"bureau\" + 0.002*\"liberal\" + 0.001*\"secondary\" + 0.001*\"project\" + 0.001*\"assessment\" + 0.001*\"history\" + 0.001*\"hkeaa\" + 0.001*\"curriculum\" + 0.001*\"questions\" + 0.001*\"dse\" + 0.001*\"teachers\" \n",
      "\n",
      "Topic 5 \n",
      " 0.010*\"cases\" + 0.009*\"yearold\" + 0.008*\"hospital\" + 0.008*\"police\" + 0.007*\"man\" + 0.006*\"covid\" + 0.006*\"centre\" + 0.006*\"health\" + 0.005*\"confirmed\" + 0.005*\"tested\" + 0.005*\"officers\" + 0.005*\"woman\" + 0.005*\"positive\" + 0.005*\"patients\" + 0.004*\"chuang\" + 0.004*\"virus\" + 0.004*\"case\" + 0.004*\"coronavirus\" + 0.004*\"new\" + 0.004*\"found\" \n",
      "\n",
      "Topic 6 \n",
      " 0.007*\"rthk\" + 0.006*\"civil\" + 0.005*\"servants\" + 0.003*\"broadcaster\" + 0.003*\"public\" + 0.003*\"service\" + 0.003*\"station\" + 0.003*\"mtr\" + 0.003*\"programme\" + 0.003*\"observatory\" + 0.003*\"signal\" + 0.002*\"nip\" + 0.002*\"storm\" + 0.002*\"programmes\" + 0.002*\"staff\" + 0.002*\"department\" + 0.002*\"authority\" + 0.002*\"headliner\" + 0.002*\"issued\" + 0.002*\"broadcasting\" \n",
      "\n",
      "Topic 7 \n",
      " 0.014*\"government\" + 0.008*\"covid\" + 0.007*\"coronavirus\" + 0.006*\"cases\" + 0.006*\"new\" + 0.006*\"health\" + 0.005*\"measures\" + 0.004*\"public\" + 0.004*\"quarantine\" + 0.004*\"number\" + 0.004*\"testing\" + 0.004*\"virus\" + 0.003*\"percent\" + 0.003*\"staff\" + 0.003*\"authorities\" + 0.003*\"help\" + 0.003*\"home\" + 0.003*\"outbreak\" + 0.003*\"days\" + 0.003*\"social\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = readcsv(\"RTHK_ntopics\\Top Words.csv\")\n",
    "#for topic 1\n",
    "print(\"Topic 1 \\n\",g['Topic0'][1],\"\\n\")\n",
    "print(\"Topic 2 \\n\",g['Topic1'][1],\"\\n\")\n",
    "print(\"Topic 3 \\n\",g['Topic2'][1],\"\\n\")\n",
    "print(\"Topic 4 \\n\",g['Topic3'][1],\"\\n\")\n",
    "print(\"Topic 5 \\n\",g['Topic4'][1],\"\\n\")\n",
    "print(\"Topic 6 \\n\",g['Topic5'][1],\"\\n\")\n",
    "print(\"Topic 7 \\n\",g['Topic6'][1],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Documents which classify as topic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Majority of students want DSE exams postponed'</td>\n",
       "      <td>A students' group says an overwhelming majori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuen Mun kindergarten closes as kids pull out</td>\n",
       "      <td>Wellcome International Kindergarten in Tuen M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NGO urges govt to help poor with online classes</td>\n",
       "      <td>A survey has found that many grassroots stude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extended school closures weigh on parents' minds</td>\n",
       "      <td>Parents across Hong Kong are looking ahead to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESF announces rare freeze in school fees</td>\n",
       "      <td>The English Schools Foundation (ESF) has anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Govt urged to hold talks over fate of DSE exams</td>\n",
       "      <td>The government is being urged to hold discuss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In the mood for love: park pandas mate at last</td>\n",
       "      <td>There was joy at Hong Kong's shuttered Ocean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Students plan protest over use of Zoom for les...</td>\n",
       "      <td>A group representing secondary school student...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Education chief expects smooth start to DSE exams</td>\n",
       "      <td>The Education Secretary Kevin Yeung says he's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'Consider partial class resumption for all stu...</td>\n",
       "      <td>The chairman of the Hong Kong Association of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DSE exams kick off without major snags</td>\n",
       "      <td>The first day of the Diploma of Secondary Edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Frederick Ma defends Liberal Studies</td>\n",
       "      <td>Education University council chairman Frederi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Schools to start reopening from May 27</td>\n",
       "      <td>Hong Kong's school children will start going ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kevin Yeung urges school pupils to take care</td>\n",
       "      <td>The Education Secretary, Kevin Yeung, on Sund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gambling king Stanley Ho dies aged 98</td>\n",
       "      <td>Macau gambling magnate Stanley Ho, one of Asi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lack of formal Basic Law education 'merits con...</td>\n",
       "      <td>A pro-government group has carried out a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pupils happy but anxious to be back at school:...</td>\n",
       "      <td>Most students who are returning to school aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>More pupils return to school after Covid-19 cl...</td>\n",
       "      <td>Classes for primary four to secondary two stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Experts urge care, support after two student d...</td>\n",
       "      <td>Mental health experts have urged schools and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Students strike a defiant note in protest song...</td>\n",
       "      <td>Police on Friday afternoon dispersed dozens o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Concerns about training for teachers played down</td>\n",
       "      <td>An advisory body has played down concerns abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Librarians sceptical about book giveaway: survey</td>\n",
       "      <td>Eight out of ten local school librarians poll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FPA unveils new sex education books for kids</td>\n",
       "      <td>The Family Planning Association of Hong Kong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'Test takers most stressed since 2012 over res...</td>\n",
       "      <td>Students who sat this year’s university entra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DSE candidates to benefit from online counselling</td>\n",
       "      <td>With many students who sat this year's Diplom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Online distribution of DSE results 'smooth'</td>\n",
       "      <td>Both the exams body and students who sat this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Treatment on hold: families fret over Covid de...</td>\n",
       "      <td>Maxine and Gabriella are two happy, healthy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New school year to open without classes</td>\n",
       "      <td>The government said on Monday the new academi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DSE students 'feel the pinch away from school'</td>\n",
       "      <td>Concerns have been raised about students who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Catholic schools to 'teach' security, anthem law</td>\n",
       "      <td>The Catholic Diocese of Hong Kong has asked i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Kindergartens urged to instil national identity</td>\n",
       "      <td>The Education Secretary, Kevin Yeung, has cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DSE exam changes needed due to class disruptio...</td>\n",
       "      <td>The Professional Teachers Union (PTU) said ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Students mark start of school year – from home</td>\n",
       "      <td>It's a most unusual start to the school year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ocean Park dashes panda pregnancy hopes</td>\n",
       "      <td>Ocean Park has confirmed that its giant panda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CUHK academic captures 'the Oscars of science'</td>\n",
       "      <td>A Hong Kong scientist who won a top internati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Covid scare grips Tuen Mun school ahead of reo...</td>\n",
       "      <td>All the staff and 30 students of a Tuen Mun s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>For some students, back to school after months</td>\n",
       "      <td>Face-to-face classes resumed in a limited man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Tuen Mun school should have suspended classes:...</td>\n",
       "      <td>The president of the Professional Teachers' U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Jitters over new international school intake rule</td>\n",
       "      <td>Educators have criticised a government decisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Students head to classes, with fear and excite...</td>\n",
       "      <td>A section of school students returned to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>'Leave early to avoid delays due to school tra...</td>\n",
       "      <td>The Transport Department on Wednesday advised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Kids happy to be back as schools reopen for all</td>\n",
       "      <td>For many, they were just happy to get out of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Teacher struck off for pro-independence messages</td>\n",
       "      <td>The Education Bureau has cancelled the regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Decision to ban teacher 'not based on full pic...</td>\n",
       "      <td>Education sector lawmaker Ip Kin-yuen has str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>De-registered teacher 'imposed independence id...</td>\n",
       "      <td>The government has defended its unprecedented...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Teacher's sacking leaves parents divided</td>\n",
       "      <td>There were mixed feelings among parents of st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Deregistering of teacher done after proper pro...</td>\n",
       "      <td>Chief Executive Carrie Lam has described the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Kevin Yeung dismisses claims of 'lax' investig...</td>\n",
       "      <td>Education Secretary Kevin Yeung has dismissed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Education body says some topics off limits for...</td>\n",
       "      <td>The chairman of the Education Policy Concern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Schools won't be independence breeding grounds...</td>\n",
       "      <td>Chief Secretary Matthew Cheung on Sunday said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Educators warn of more student withdrawals</td>\n",
       "      <td>Educators warned on Saturday that Hong Kong s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Teachers need independent body: Ip Kin-yuen</td>\n",
       "      <td>The lawmaker representing the education secto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Schools 'push back against anonymous complaints'</td>\n",
       "      <td>Many school principals say they are pushing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Teacher struck off over dodgy history lessons:...</td>\n",
       "      <td>The Education Bureau has de-registered a prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>'De-registered teacher was kind and always jok...</td>\n",
       "      <td>Parents were divided on Friday as to whether ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>History isn't my subject, says de-registered t...</td>\n",
       "      <td>A primary school teacher struck off because o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Schools to suspend classes for the rest of the...</td>\n",
       "      <td>All schools at the secondary level and below ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>'Law-abidingness', empathy now core values at ...</td>\n",
       "      <td>The Education Bureau has made what it called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Poor students face uphill task with online cla...</td>\n",
       "      <td>Local students are back to having their class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>School suspension extended until January 10</td>\n",
       "      <td>The government said on Monday that schools wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0     'Majority of students want DSE exams postponed'   \n",
       "1       Tuen Mun kindergarten closes as kids pull out   \n",
       "2     NGO urges govt to help poor with online classes   \n",
       "3    Extended school closures weigh on parents' minds   \n",
       "4            ESF announces rare freeze in school fees   \n",
       "5     Govt urged to hold talks over fate of DSE exams   \n",
       "6      In the mood for love: park pandas mate at last   \n",
       "7   Students plan protest over use of Zoom for les...   \n",
       "8   Education chief expects smooth start to DSE exams   \n",
       "9   'Consider partial class resumption for all stu...   \n",
       "10             DSE exams kick off without major snags   \n",
       "11               Frederick Ma defends Liberal Studies   \n",
       "12             Schools to start reopening from May 27   \n",
       "13       Kevin Yeung urges school pupils to take care   \n",
       "14              Gambling king Stanley Ho dies aged 98   \n",
       "15  Lack of formal Basic Law education 'merits con...   \n",
       "16  Pupils happy but anxious to be back at school:...   \n",
       "17  More pupils return to school after Covid-19 cl...   \n",
       "18  Experts urge care, support after two student d...   \n",
       "19  Students strike a defiant note in protest song...   \n",
       "20   Concerns about training for teachers played down   \n",
       "21   Librarians sceptical about book giveaway: survey   \n",
       "22       FPA unveils new sex education books for kids   \n",
       "23  'Test takers most stressed since 2012 over res...   \n",
       "24  DSE candidates to benefit from online counselling   \n",
       "25        Online distribution of DSE results 'smooth'   \n",
       "26  Treatment on hold: families fret over Covid de...   \n",
       "27            New school year to open without classes   \n",
       "28     DSE students 'feel the pinch away from school'   \n",
       "29   Catholic schools to 'teach' security, anthem law   \n",
       "30    Kindergartens urged to instil national identity   \n",
       "31  DSE exam changes needed due to class disruptio...   \n",
       "32     Students mark start of school year – from home   \n",
       "33            Ocean Park dashes panda pregnancy hopes   \n",
       "34     CUHK academic captures 'the Oscars of science'   \n",
       "35  Covid scare grips Tuen Mun school ahead of reo...   \n",
       "36     For some students, back to school after months   \n",
       "37  Tuen Mun school should have suspended classes:...   \n",
       "38  Jitters over new international school intake rule   \n",
       "39  Students head to classes, with fear and excite...   \n",
       "40  'Leave early to avoid delays due to school tra...   \n",
       "41    Kids happy to be back as schools reopen for all   \n",
       "42   Teacher struck off for pro-independence messages   \n",
       "43  Decision to ban teacher 'not based on full pic...   \n",
       "44  De-registered teacher 'imposed independence id...   \n",
       "45           Teacher's sacking leaves parents divided   \n",
       "46  Deregistering of teacher done after proper pro...   \n",
       "47  Kevin Yeung dismisses claims of 'lax' investig...   \n",
       "48  Education body says some topics off limits for...   \n",
       "49  Schools won't be independence breeding grounds...   \n",
       "50         Educators warn of more student withdrawals   \n",
       "51        Teachers need independent body: Ip Kin-yuen   \n",
       "52   Schools 'push back against anonymous complaints'   \n",
       "53  Teacher struck off over dodgy history lessons:...   \n",
       "54  'De-registered teacher was kind and always jok...   \n",
       "55  History isn't my subject, says de-registered t...   \n",
       "56  Schools to suspend classes for the rest of the...   \n",
       "57  'Law-abidingness', empathy now core values at ...   \n",
       "58  Poor students face uphill task with online cla...   \n",
       "59        School suspension extended until January 10   \n",
       "\n",
       "                                               Corpus  \n",
       "0    A students' group says an overwhelming majori...  \n",
       "1    Wellcome International Kindergarten in Tuen M...  \n",
       "2    A survey has found that many grassroots stude...  \n",
       "3    Parents across Hong Kong are looking ahead to...  \n",
       "4    The English Schools Foundation (ESF) has anno...  \n",
       "5    The government is being urged to hold discuss...  \n",
       "6    There was joy at Hong Kong's shuttered Ocean ...  \n",
       "7    A group representing secondary school student...  \n",
       "8    The Education Secretary Kevin Yeung says he's...  \n",
       "9    The chairman of the Hong Kong Association of ...  \n",
       "10   The first day of the Diploma of Secondary Edu...  \n",
       "11   Education University council chairman Frederi...  \n",
       "12   Hong Kong's school children will start going ...  \n",
       "13   The Education Secretary, Kevin Yeung, on Sund...  \n",
       "14   Macau gambling magnate Stanley Ho, one of Asi...  \n",
       "15   A pro-government group has carried out a new ...  \n",
       "16   Most students who are returning to school aft...  \n",
       "17   Classes for primary four to secondary two stu...  \n",
       "18   Mental health experts have urged schools and ...  \n",
       "19   Police on Friday afternoon dispersed dozens o...  \n",
       "20   An advisory body has played down concerns abo...  \n",
       "21   Eight out of ten local school librarians poll...  \n",
       "22   The Family Planning Association of Hong Kong ...  \n",
       "23   Students who sat this year’s university entra...  \n",
       "24   With many students who sat this year's Diplom...  \n",
       "25   Both the exams body and students who sat this...  \n",
       "26   Maxine and Gabriella are two happy, healthy t...  \n",
       "27   The government said on Monday the new academi...  \n",
       "28   Concerns have been raised about students who ...  \n",
       "29   The Catholic Diocese of Hong Kong has asked i...  \n",
       "30   The Education Secretary, Kevin Yeung, has cal...  \n",
       "31   The Professional Teachers Union (PTU) said ad...  \n",
       "32   It's a most unusual start to the school year ...  \n",
       "33   Ocean Park has confirmed that its giant panda...  \n",
       "34   A Hong Kong scientist who won a top internati...  \n",
       "35   All the staff and 30 students of a Tuen Mun s...  \n",
       "36   Face-to-face classes resumed in a limited man...  \n",
       "37   The president of the Professional Teachers' U...  \n",
       "38   Educators have criticised a government decisi...  \n",
       "39   A section of school students returned to the ...  \n",
       "40   The Transport Department on Wednesday advised...  \n",
       "41   For many, they were just happy to get out of ...  \n",
       "42   The Education Bureau has cancelled the regist...  \n",
       "43   Education sector lawmaker Ip Kin-yuen has str...  \n",
       "44   The government has defended its unprecedented...  \n",
       "45   There were mixed feelings among parents of st...  \n",
       "46   Chief Executive Carrie Lam has described the ...  \n",
       "47   Education Secretary Kevin Yeung has dismissed...  \n",
       "48   The chairman of the Education Policy Concern ...  \n",
       "49   Chief Secretary Matthew Cheung on Sunday said...  \n",
       "50   Educators warned on Saturday that Hong Kong s...  \n",
       "51   The lawmaker representing the education secto...  \n",
       "52   Many school principals say they are pushing b...  \n",
       "53   The Education Bureau has de-registered a prim...  \n",
       "54   Parents were divided on Friday as to whether ...  \n",
       "55   A primary school teacher struck off because o...  \n",
       "56   All schools at the secondary level and below ...  \n",
       "57   The Education Bureau has made what it called ...  \n",
       "58   Local students are back to having their class...  \n",
       "59   The government said on Monday that schools wi...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save all document which has been classified \n",
    "import os\n",
    "def save_csv(directory, Topic_corpus, best_topics):\n",
    "    directory = \"\\\\\" + directory\n",
    "    for i in range(best_topics):\n",
    "    \n",
    "        pd.DataFrame(Topic_corpus[i]).to_csv(f\"{os.getcwd()}{directory}\\Topic{i}.csv\", index=False)\n",
    "        \n",
    "#save_csv(\"RTHK_ntopics\", e, f)\n",
    "\n",
    "readcsv(\"RTHK_ntopics\\Topic0.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
